# ü§ñ Automatizaci√≥n del Scraper - DealTech365

Sistema completo de automatizaci√≥n para mantener las ofertas siempre actualizadas.

## üìã Tabla de Contenidos

1. [Qu√© hace](#qu√©-hace)
2. [Requisitos](#requisitos)
3. [Instalaci√≥n](#instalaci√≥n)
4. [Configuraci√≥n](#configuraci√≥n)
5. [Uso Manual](#uso-manual)
6. [Automatizaci√≥n Diaria](#automatizaci√≥n-diaria)
7. [FTP Autom√°tico (Opcional)](#ftp-autom√°tico-opcional)
8. [Troubleshooting](#troubleshooting)

---

## üéØ Qu√© hace

El sistema de automatizaci√≥n:

1. ‚úÖ **Ejecuta el scraper** de Amazon para obtener ofertas frescas
2. ‚úÖ **Genera `deals-real-v2.js`** autom√°ticamente con los nuevos datos
3. ‚úÖ **Hace commit y push** a GitHub
4. ‚úÖ **Sube a Banahosting** v√≠a FTP (opcional)
5. ‚úÖ **Registra logs** de todas las operaciones
6. ‚úÖ **Reintenta** en caso de errores

---

## üì¶ Requisitos

### Esenciales:
- ‚úÖ Node.js (ya instalado)
- ‚úÖ Git configurado
- ‚úÖ Proyecto clonado en `c:\Dealtech365`

### Opcionales (para FTP):
- npm package: `basic-ftp`

---

## üöÄ Instalaci√≥n

### Paso 1: Verificar estructura de carpetas

```bash
cd c:\Dealtech365
dir automation\scripts
```

Deber√≠as ver:
- `auto-scrape-and-update.js` ‚úÖ
- `upload-to-banahosting.js` ‚úÖ

### Paso 2: Crear carpeta de logs

```bash
mkdir automation\logs
```

### Paso 3: (Opcional) Instalar dependencia FTP

```bash
npm install basic-ftp
```

---

## ‚öôÔ∏è Configuraci√≥n

### Git (Verificar que est√© configurado)

```bash
git config --global user.name "Tu Nombre"
git config --global user.email "tu@email.com"
```

### FTP (Solo si quieres auto-upload)

Crea un archivo `.env` en `c:\Dealtech365\`:

```env
FTP_HOST=ftp.dealtech365.com
FTP_USER=tu_usuario_ftp
FTP_PASSWORD=tu_contrase√±a_ftp
FTP_PORT=21
```

‚ö†Ô∏è **IMPORTANTE**: Nunca subas `.env` a GitHub (ya est√° en `.gitignore`)

---

## üîß Uso Manual

### Ejecutar el scraper y actualizar todo:

```bash
cd c:\Dealtech365
node automation\scripts\auto-scrape-and-update.js
```

Esto har√°:
1. Scraping de Amazon (2-5 minutos)
2. Generar `deals-real-v2.js`
3. Commit y push a GitHub

### Solo subir a Banahosting (despu√©s de actualizar):

```bash
node automation\scripts\upload-to-banahosting.js
```

---

## ‚è∞ Automatizaci√≥n Diaria

### Windows Task Scheduler

#### Opci√≥n 1: Script R√°pido (Recomendado)

1. **Abre PowerShell como Administrador**

2. **Ejecuta este comando:**

```powershell
$action = New-ScheduledTaskAction -Execute "c:\Dealtech365\automation\run-daily-scraper.bat"
$trigger = New-ScheduledTaskTrigger -Daily -At 3:00AM
$settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries
Register-ScheduledTask -TaskName "DealTech365 Daily Scraper" -Action $action -Trigger $trigger -Settings $settings -Description "Actualiza ofertas diariamente a las 3 AM"
```

3. **Verificar:**

```powershell
Get-ScheduledTask -TaskName "DealTech365 Daily Scraper"
```

#### Opci√≥n 2: Interfaz Gr√°fica

1. **Abrir Programador de Tareas:**
   - Presiona `Win + R`
   - Escribe: `taskschd.msc`
   - Enter

2. **Crear Tarea B√°sica:**
   - Click derecho en "Biblioteca del Programador de Tareas"
   - "Crear tarea b√°sica..."

3. **Configurar:**
   - **Nombre:** `DealTech365 Daily Scraper`
   - **Desencadenador:** Diariamente a las 3:00 AM
   - **Acci√≥n:** Iniciar un programa
   - **Programa:** `c:\Dealtech365\automation\run-daily-scraper.bat`

4. **Opciones Avanzadas:**
   - ‚úÖ Ejecutar con los privilegios m√°s altos
   - ‚úÖ Ejecutar aunque el usuario no haya iniciado sesi√≥n
   - ‚úÖ Ejecutar s√≥lo si hay conexi√≥n a internet

#### Horario Recomendado

**3:00 AM** es ideal porque:
- ‚úÖ Menos tr√°fico en Amazon
- ‚úÖ Ofertas ya actualizadas del d√≠a
- ‚úÖ Tu computadora probablemente est√© encendida
- ‚úÖ Visitantes europeos ven ofertas frescas al despertar

---

## üì§ FTP Autom√°tico (Opcional)

### M√©todo 1: Incluir en el script principal

Edita `auto-scrape-and-update.js` y agrega al final (antes de `process.exit(0)`):

```javascript
// Paso 5: Upload to Banahosting
if (process.env.ENABLE_FTP_UPLOAD === 'true') {
  const { uploadFiles } = require('./upload-to-banahosting');
  await uploadFiles();
}
```

Luego agrega a `.env`:
```env
ENABLE_FTP_UPLOAD=true
```

### M√©todo 2: Tarea separada

Crea una segunda tarea programada que ejecute 5 minutos despu√©s:

```powershell
$action = New-ScheduledTaskAction -Execute "node" -Argument "c:\Dealtech365\automation\scripts\upload-to-banahosting.js"
$trigger = New-ScheduledTaskTrigger -Daily -At 3:05AM
Register-ScheduledTask -TaskName "DealTech365 FTP Upload" -Action $action -Trigger $trigger
```

---

## üìä Verificar que funciona

### 1. Ver logs

```bash
type automation\logs\auto-update.log
type automation\logs\scheduler.log
```

### 2. Verificar √∫ltima ejecuci√≥n

```bash
git log --oneline -5
```

Deber√≠as ver commits autom√°ticos con:
```
Auto-update deals from scraper - 2025-11-29T03:00:00.000Z
```

### 3. Verificar archivo generado

```bash
type js\deals-real-v2.js | findstr "Last update"
```

Deber√≠a mostrar la fecha de hoy.

---

## üîç Troubleshooting

### Problema: "No se encontraron archivos JSON"

**Causa:** El scraper no gener√≥ datos

**Soluci√≥n:**
```bash
node automation\scraper\amazon-scraper-improved.js
```

Verifica que genere `automation\data\deals-ES-*.json`

---

### Problema: "Git push failed"

**Causa:** Credenciales o permisos

**Soluci√≥n:**
```bash
git config credential.helper store
git push
# Ingresa tus credenciales una vez
```

---

### Problema: "FTP connection refused"

**Causa:** Credenciales incorrectas o firewall

**Soluci√≥n:**
1. Verifica `.env` tiene las credenciales correctas
2. Prueba conexi√≥n FTP manual con FileZilla
3. Verifica puerto (21 para FTP, 22 para SFTP)

---

### Problema: Task Scheduler no ejecuta

**Causa:** Configuraci√≥n de permisos

**Soluci√≥n:**
1. Click derecho en la tarea ‚Üí Propiedades
2. Pesta√±a "General"
3. ‚úÖ "Ejecutar con los privilegios m√°s altos"
4. ‚úÖ "Ejecutar aunque el usuario no haya iniciado sesi√≥n"

---

## üìà Mejoras Futuras

### Ideas para expandir:

1. **Notificaciones por email** cuando hay errores
2. **Webhook a Discord/Slack** con resumen diario
3. **Gr√°ficos de precio hist√≥rico** almacenando cada scrape
4. **Detecci√≥n de mejores ofertas** (mayor descuento)
5. **Multiple sources** (no solo Amazon)
6. **Deploy autom√°tico** a Netlify/Vercel

---

## üìù Resumen de Comandos

```bash
# Ejecutar scraper + actualizaci√≥n manual
node automation\scripts\auto-scrape-and-update.js

# Solo subir a FTP
node automation\scripts\upload-to-banahosting.js

# Ver logs
type automation\logs\auto-update.log

# Verificar tarea programada
Get-ScheduledTask -TaskName "DealTech365 Daily Scraper"

# Forzar ejecuci√≥n inmediata de tarea
Start-ScheduledTask -TaskName "DealTech365 Daily Scraper"
```

---

## üéâ ¬°Listo!

Ahora tu sitio tendr√° **ofertas frescas autom√°ticamente cada d√≠a** sin intervenci√≥n manual.

Las ofertas se actualizar√°n:
- ‚úÖ Autom√°ticamente cada d√≠a a las 3 AM
- ‚úÖ Se subir√°n a GitHub
- ‚úÖ (Opcional) Se desplegar√°n a Banahosting

**¬øPreguntas?** Revisa los logs en `automation\logs\`
